{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04c5838c",
   "metadata": {},
   "source": [
    "# DBAP CA2\n",
    "## Jia Lin 22117644 teamC\n",
    "## TABLE 3: The US Confirmed and Death by Provinces\n",
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "68311359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests             # library request is used to fetch data from API \n",
    "import json                 # library json is used load json objects\n",
    "import datetime             # library datetime is used to convert between datetime and string\n",
    "from datetime import date\n",
    "import pymongo              # library pymongo is used to build connection with MongoDB\n",
    "import pandas               # library pandas is used to create a ETL pipeline\n",
    "import psycopg2             # library psycopg2 is used to make connection with PostgreSQL\n",
    "import csv                  # library csv is used to store csv to PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b32339",
   "metadata": {},
   "source": [
    "### Function Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6698be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getResponse function is defined to get response from web \"url\" based on \"query\"\n",
    "def getResponse(url, query):\n",
    "    return requests.request(\"GET\", url, headers=headers, params=query)\n",
    "\n",
    "# getJSON_obj function is defined to get a json object based on \"response\"\n",
    "def getJSON_obj(response):\n",
    "    return json.loads(response.content.decode(\"utf-8\"))\n",
    "\n",
    "# get_data_value function is defined to return the value of key data\n",
    "def get_data_value(url, query):\n",
    "    json_obj = getJSON_obj(getResponse(url, query))[\"data\"]\n",
    "    #if len(json_obj) == 0: \n",
    "     #   print(\"Notice: there is no data on this date!\")\n",
    "    return json_obj\n",
    "\n",
    "# get_data_values function is defined to get a list of json values of key data\n",
    "# For each json_obj, there is a json_obj[\"data\"]\n",
    "# This function will return a list of json_obj[\"data\"]\n",
    "# based on a list of queries from a specific url\n",
    "def get_data_values(url, query_list):\n",
    "    return [get_data_value(url, q) for q in query_list]\n",
    "\n",
    "# a_day_before function is defined to get the date of one day before the day_date\n",
    "def a_day_before(day_date): \n",
    "    return day_date - datetime.timedelta(days=1)\n",
    "\n",
    "# str_to_date function is defined to convert a string to a date\n",
    "def str_to_date(s): \n",
    "    return datetime.datetime.strptime(s, '%Y-%m-%d %H:%M:%S').date()\n",
    "\n",
    "# date_to_str function is defined to convert a date to a string\n",
    "def date_to_str(dt): \n",
    "    return dt.strftime('%Y-%m-%d')  \n",
    "\n",
    "# get_date_list function is defined to return a list of date in string format\n",
    "# by given the start_date and the number of days\n",
    "def get_date_list(start_date, number_of_days):\n",
    "    date_datetype_list = [start_date - datetime.timedelta(days=x) for x in range(number_of_days)]\n",
    "    return [date_to_str(x) for x in date_datetype_list]\n",
    "\n",
    "def get_csv(collection_name, csv_file_name):\n",
    "    cursors = collection_name.find()\n",
    "    # Convert the mongo documents to a DataFrame\n",
    "    documents = pandas.DataFrame(cursors)\n",
    "    # Discard the Mongo ID for the documents\n",
    "    documents.pop(\"_id\")\n",
    "    # export MongoDB documents to a csv file, leaving out the row \"labels\" (row numbers)\n",
    "    documents.to_csv(csv_file_name, \",\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c70092",
   "metadata": {},
   "source": [
    "## ETL pipeline: Extract\n",
    "### Fetch Data from API (Extract)\n",
    "#### Two Queries:\n",
    "#### 1) Query for US Provinces or State\n",
    "#### 2) Query for Covid-19 Data in Cities of Each Province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e0106b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source code: https://rapidapi.com/axisbits-axisbits-default/api/covid-19-statistics/\n",
    "# Based on public data by Johns Hopkins CSSE\n",
    "# In terms of the requirements of this project, Jia Lin made some modifications on the source code\n",
    "headers = {\"X-RapidAPI-Key\": \"bc72ee8736mshfc960795af3b6ddp15d851jsn50353bd76099\",\n",
    "           \"X-RapidAPI-Host\": \"covid-19-statistics.p.rapidapi.com\"}\n",
    "\n",
    "# List of provinces by country ISO code.\n",
    "url_provinces = \"https://covid-19-statistics.p.rapidapi.com/provinces\"\n",
    "query_iso = {\"iso\":\"USA\"}\n",
    "# Original data from API \n",
    "provinces = get_data_value(url_provinces, query_iso)\n",
    "#print(provinces[0])\n",
    "\n",
    "# Reports by date an country/province. \n",
    "# Cities data is available for the USA only.\n",
    "url_US_reports = \"https://covid-19-statistics.p.rapidapi.com/reports\"\n",
    "query_US_reports = {\"iso\":\"USA\",\"date\":\"2022-12-06\"}\n",
    "# In this query, the date is an vital parameter\n",
    "# Normally, the latest data is a day before current date\n",
    "data_value_US_reports = get_data_value(url_US_reports, query_US_reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4ba276",
   "metadata": {},
   "source": [
    "## ETL pipeline: Transform\n",
    "### Get Covid-19 Info for All US Province\n",
    "#### The aim of this section is clean and transform the data\n",
    "#### The instance will not be collected, when meet any issue below:\n",
    "#### 1) If the province itself has no value to present.\n",
    "#### 2) If the province has no cities info to show\n",
    "#### 3) If some irrelevant attributes are found, for eample, wrong city name, empty value (None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "97ac1504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of queries with different province\n",
    "# Be careful with the date\n",
    "def get_query_province(province):\n",
    "    return {\"region_province\": province ,\"iso\":\"USA\", \"date\":\"2022-12-06\"}\n",
    "\n",
    "provinces_name_list = [p[\"province\"] for p in provinces]\n",
    "\n",
    "no_match_provinces = []# province in this list has no info to present\n",
    "matching_provinces = []# province in this list contain data to present\n",
    "provinces_info_list = []# a list of list of cities of each province\n",
    "for province_name in provinces_name_list:\n",
    "    # report is a list of length of 0 or 1\n",
    "    # when length is 0 indicates no match province info \n",
    "    report = get_data_value(url_US_reports, get_query_province(province_name))\n",
    "    if len(report) == 0:# this province has no info\n",
    "        no_match_provinces.append(province_name)\n",
    "        continue\n",
    "    if len(report) == 1:  \n",
    "        kv = {\"province\": report[0][\"region\"][\"province\"]}\n",
    "        cities = report[0][\"region\"][\"cities\"]\n",
    "        if len(cities) == 0:# this province has no cities info\n",
    "            no_match_provinces.append(province_name)\n",
    "        else:\n",
    "            matching_provinces.append(province_name)\n",
    "            for city in cities: \n",
    "                if city['name'] == 'Unassigned' or city['lat'] is None or city['fips'] is None:\n",
    "                    continue\n",
    "                else: \n",
    "                    city.update(kv)\n",
    "                    provinces_info_list.append(city)\n",
    "    else: print(\"There is an error, the len is eigher 1 or 0.\")\n",
    "\n",
    "############################################################################################\n",
    "# There are two kinds of provinces in this no_match_province\n",
    "# One is this province has no info\n",
    "# The other one is this province has no cities info\n",
    "############################################################################################\n",
    "# Clean data provinces\n",
    "# Only the provinces with data will be maintained\n",
    "def isMatchingProvinces(str):\n",
    "    for name in matching_provinces:\n",
    "        if str == name:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "new_provinces = []\n",
    "for item in provinces:\n",
    "    if isMatchingProvinces(item[\"province\"]):\n",
    "        new_provinces.append(item)\n",
    "    else: continue\n",
    "# This new_provinces will be stored in MongoDB\n",
    "#print(new_provinces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55934a21",
   "metadata": {},
   "source": [
    "### Making a Connection with MongoDB\n",
    "#### Two collections related to provinces\n",
    "#### 1) provinces_of_US_collection\n",
    "#### 2) reports_US_provinces_cities_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f7eb09f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db names: ['admin', 'config', 'jialin_Mongo_database', 'local', 'test_database']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['global_date_over_time_collection',\n",
       " 'provinces_of_US_collection',\n",
       " 'reports_US_data_over_time_collection',\n",
       " 'reports_US_provinces_cities_collection']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source code: DBAP_Lab_Week6 (MogoDB)\n",
    "client = pymongo.MongoClient('localhost', 27017)\n",
    "# create a database called jialin_Mongo_database (may change to covid19JHCSSE_database)\n",
    "db = client.jialin_Mongo_database\n",
    "# create a cellections\n",
    "provinces_of_US_collection = db.provinces_of_US_collection\n",
    "reports_US_provinces_cities_collection = db.reports_US_provinces_cities_collection\n",
    "\n",
    "provinces_of_US_collection.drop()\n",
    "reports_US_provinces_cities_collection.drop()\n",
    "\n",
    "# Insert more than 1 docuement using insert_many method\n",
    "# collection 3\n",
    "# Note that it is new_provinces list\n",
    "provinces_of_US_collection.insert_many(new_provinces)\n",
    "# collection 4\n",
    "reports_US_provinces_cities_collection.insert_many(provinces_info_list)\n",
    "\n",
    "database_list = client.list_database_names()\n",
    "print (\"db names:\", database_list)\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae6f381",
   "metadata": {},
   "source": [
    "## ETL pipeline: Transform\n",
    "### JSON to CSV\n",
    "### Export CSV File from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "beb4efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_csv(provinces_of_US_collection, \"DBAP_CA2_provinces_US.csv\")\n",
    "get_csv(reports_US_provinces_cities_collection, \"DBAP_CA2_reports_US_provinces_cities.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
