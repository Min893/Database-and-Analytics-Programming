{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e8522db",
   "metadata": {},
   "source": [
    "# DBAP CA2\n",
    "## Jia Lin 22117644 teamC\n",
    "## TABLE 1: Global Covid-19 Data Over Time\n",
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0ebb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests             # library request is used to fetch data from API \n",
    "import json                 # library json is used load json objects\n",
    "import datetime             # library datetime is used to convert between datetime and string\n",
    "from datetime import date\n",
    "import pymongo              # library pymongo is used to build connection with MongoDB\n",
    "import pandas               # library pandas is used to create a ETL pipeline\n",
    "import psycopg2             # library psycopg2 is used to make connection with PostgreSQL\n",
    "import csv                  # library csv is used to store csv to PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8469c251",
   "metadata": {},
   "source": [
    "### Function Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec05fa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getResponse function is defined to get response from web \"url\" based on \"query\"\n",
    "def getResponse(url, query):\n",
    "    return requests.request(\"GET\", url, headers=headers, params=query)\n",
    "\n",
    "# getJSON_obj function is defined to get a json object based on \"response\"\n",
    "def getJSON_obj(response):\n",
    "    return json.loads(response.content.decode(\"utf-8\"))\n",
    "\n",
    "# get_data_value function is defined to return the value of key data\n",
    "def get_data_value(url, query):\n",
    "    json_obj = getJSON_obj(getResponse(url, query))[\"data\"]\n",
    "    if len(json_obj) == 0:\n",
    "        print(\"Notice: there is no data on this date!\")\n",
    "    return json_obj\n",
    "\n",
    "# get_data_values function is defined to get a list of json values of key data\n",
    "# For each json_obj, there is a json_obj[\"data\"]\n",
    "# This function will return a list of json_obj[\"data\"]\n",
    "# based on a list of queries from a specific url\n",
    "def get_data_values(url, query_list):\n",
    "    return [get_data_value(url, q) for q in query_list]\n",
    "\n",
    "\n",
    "# a_day_before function is defined to get the date of one day before the day_date\n",
    "def a_day_before(day_date): \n",
    "    return day_date - datetime.timedelta(days=1)\n",
    "\n",
    "# str_to_date function is defined to convert a string to a date\n",
    "def str_to_date(s): \n",
    "    return datetime.datetime.strptime(s, '%Y-%m-%d %H:%M:%S').date()\n",
    "\n",
    "# date_to_str function is defined to convert a date to a string\n",
    "def date_to_str(dt): \n",
    "    return dt.strftime('%Y-%m-%d')  \n",
    "\n",
    "# get_date_list function is defined to return a list of date in string format\n",
    "# by given the start_date and the number of days\n",
    "def get_date_list(start_date, number_of_days):\n",
    "    date_datetype_list = [start_date - datetime.timedelta(days=x) for x in range(number_of_days)]\n",
    "    return [date_to_str(x) for x in date_datetype_list]\n",
    "\n",
    "def get_csv(collection_name, csv_file_name):\n",
    "    cursors = collection_name.find()\n",
    "    # Convert the mongo documents to a DataFrame\n",
    "    documents = pandas.DataFrame(cursors)\n",
    "    # Discard the Mongo ID for the documents\n",
    "    documents.pop(\"_id\")\n",
    "    # export MongoDB documents to a csv file, leaving out the row \"labels\" (row numbers)\n",
    "    documents.to_csv(csv_file_name, \",\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dece37",
   "metadata": {},
   "source": [
    "## ETL pipeline: Extract\n",
    "### Fetch Data from API (Extract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1761dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Covid-19 data for global: \n",
      "{'date': '2022-12-06', 'last_update': '2022-12-07 04:20:58', 'confirmed': 646353483, 'confirmed_diff': 591721, 'deaths': 6644784, 'deaths_diff': 2621, 'recovered': 0, 'recovered_diff': 0, 'active': 639708699, 'active_diff': 589100, 'fatality_rate': 0.0103}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Source code: https://rapidapi.com/axisbits-axisbits-default/api/covid-19-statistics/\n",
    "# Based on public data by Johns Hopkins CSSE\n",
    "# In terms of the requirements of this project, Jia Lin made some modifications on the source code\n",
    "headers = {\"X-RapidAPI-Key\": \"bc72ee8736mshfc960795af3b6ddp15d851jsn50353bd76099\",\n",
    "           \"X-RapidAPI-Host\": \"covid-19-statistics.p.rapidapi.com\"}\n",
    "\n",
    "# Total data for the entire world for particular date\n",
    "# In terms of data in API, the result is a day before current date\n",
    "url_total = \"https://covid-19-statistics.p.rapidapi.com/reports/total\"\n",
    "query_date = {\"date\":\"2022-12-06\"}\n",
    "# The date is an vital parameter\n",
    "# If the API haven't be updated, there is no value to present. \n",
    "data_value_total = get_data_value(url_total, query_date)\n",
    "print(\"The Covid-19 data for global: \\n{}\\n\".format(data_value_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98616467",
   "metadata": {},
   "source": [
    "### Collect Data for 1000 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336dd48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query days for global = 1000\n"
     ]
    }
   ],
   "source": [
    "# The number_of_days_for_global is the number of instances (or rows) of global info\n",
    "# it must be greater than or equal to 1\n",
    "# China reports the Covid-19 in 31 Dec. 2019.\n",
    "# Hence we collect the data from Jan. 2020\n",
    "# Hence, maximum value of the number_of_days is approximate 1030 (1070 until 05/12/22)\n",
    "number_of_days_for_global = 1000\n",
    "if number_of_days_for_global < 1:\n",
    "    print(\"The query day must be more than 1, number_of_day = {}\".format(number_of_days_for_global))\n",
    "elif number_of_days_for_global >1030:\n",
    "    print(\"The query day must be less than or equal to 1030, number_of_days = {}\".format(number_of_days_for_global))\n",
    "else:\n",
    "    print(\"The query days for global = {}\".format(number_of_days_for_global))\n",
    "\n",
    "# a list of date queries   \n",
    "date_list_for_global = get_date_list(str_to_date(\"2022-12-06 00:00:00\"), number_of_days_for_global)\n",
    "query_date_list_for_global = [{\"date\":x} for x in date_list_for_global]\n",
    "#print(query_date_list_for_global)        \n",
    "    \n",
    "# list of global data info over time\n",
    "# This list can be inserted to MongoDB as a collection\n",
    "global_data_over_time_list = get_data_values(url_total, query_date_list_for_global)\n",
    "\n",
    "#for row in global_data_over_time_list:\n",
    "#    print(row)\n",
    "#print(global_data_over_time_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ce4dcf",
   "metadata": {},
   "source": [
    "## ETL pipeline: Transform\n",
    "### Making a Connection with MongoDB\n",
    "#### One Collection is Created: \n",
    "#### global_date_over_time_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08886554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database names:\n",
      "admin\n",
      "config\n",
      "jialin_Mongo_database\n",
      "local\n",
      "test_database\n",
      "\n",
      "\n",
      "collection names:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['global_date_over_time_collection',\n",
       " 'reports_US_data_over_time_collection',\n",
       " 'provinces_of_US_collection',\n",
       " 'reports_US_provinces_cities_collection']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source code: DBAP_Lab_Week6 (MogoDB)\n",
    "client = pymongo.MongoClient('localhost', 27017)\n",
    "# create a database called jialin_Mongo_database (may change to covid19JHCSSE_database)\n",
    "db = client.jialin_Mongo_database\n",
    "# create a cellections\n",
    "global_data_over_time_collection = db.global_date_over_time_collection\n",
    "global_data_over_time_collection.drop()\n",
    "# Insert more than 1 docuement using insert_many method\n",
    "# collection 1\n",
    "global_data_over_time_collection.insert_many(global_data_over_time_list)\n",
    "\n",
    "database_list = client.list_database_names()\n",
    "print(\"database names:\")\n",
    "for database in database_list:\n",
    "    print(database)\n",
    "print(\"\\n\")    \n",
    "print(\"collection names:\")\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c554c012",
   "metadata": {},
   "source": [
    "## ETL pipeline: Transform\n",
    "### JSON to CSV\n",
    "### Export CSV File from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_csv(global_data_over_time_collection, \"DBAP_CA2_global_data_over_time.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
